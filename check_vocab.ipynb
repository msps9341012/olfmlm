{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tz = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model weights\n",
    "method='max_vocab'\n",
    "model_sd = torch.load('pretrained_berts_{}/mf+mlm/best/model.pt'.format(method), map_location='cpu')\n",
    "word_emb = model_sd['sd']['bert.embeddings.word_embeddings.weight'].cpu().numpy()\n",
    "\n",
    "\n",
    "#load facet's vector\n",
    "view_1=np.load('embeds/{}/view_1.npy'.format(method))\n",
    "view_2=np.load('embeds/{}/view_2.npy'.format(method))\n",
    "view_3=np.load('embeds/{}/view_3.npy'.format(method))\n",
    "\n",
    "#load raw text (validation set)\n",
    "import pickle\n",
    "with open('embeds/raw_val.pkl', 'rb') as handle:\n",
    "    raw_text = pickle.load(handle)\n",
    "\n",
    "total_examples=len(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-joint",
   "metadata": {},
   "source": [
    "### For each facet, find the nearset token among all the bert vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use faiss lib to do the nearset neighbor search\n",
    "#see here (https://github.com/facebookresearch/faiss/issues/95#issuecomment-714562162)\n",
    "\n",
    "#build required index \n",
    "index = faiss.index_factory(768, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "faiss.normalize_L2(word_emb)\n",
    "index.add(word_emb)\n",
    "\n",
    "faiss.normalize_L2(view_1)\n",
    "faiss.normalize_L2(view_2)\n",
    "faiss.normalize_L2(view_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor(query,text_id,n):\n",
    "    q = np.expand_dims(query[text_id],axis=0)\n",
    "    '''\n",
    "    D: distance\n",
    "    I: neighbor index, here is token index\n",
    "    '''\n",
    "    D, I =index.search(q, n)\n",
    "    words=[]\n",
    "    for i in I[0]:\n",
    "        #token index -> word\n",
    "        words+=tz.convert_ids_to_tokens([i])\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the top-n nearset neighbors for each facet\n",
    "\n",
    "import random\n",
    "n=5\n",
    "choose_id = random.randint(0,total_examples-1)\n",
    "print('Query:', raw_text[choose_id])\n",
    "print('\\n')\n",
    "\n",
    "print('Facet 1')\n",
    "print(get_neighbor(view_1,choose_id,n))\n",
    "print('\\n')\n",
    "\n",
    "print('Facet 2')\n",
    "print(get_neighbor(view_2,choose_id,n))\n",
    "print('\\n')\n",
    "\n",
    "print('Facet 3')\n",
    "print(get_neighbor(view_3,choose_id,n))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
