{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import psutil\n",
    "import torch\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from olfmlm.configure_data import configure_data\n",
    "from olfmlm.model import BertModel\n",
    "from olfmlm.optim import Adam\n",
    "from olfmlm.utils import save_checkpoint\n",
    "from olfmlm.utils import load_checkpoint\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=Namespace(alternating=False, always_mlm=True, attention_dropout=0.1, batch_size=16, bert_config_file='bert_config.json', cache_dir='cache_dir', checkpoint_activations=False, clip_grad=1.0, continual_learning=False, cuda=True, delim=',', distributed_backend='nccl', dynamic_loss_scale=True, epochs=32, eval_batch_size=None, eval_iters=2000, eval_max_preds_per_seq=None, eval_seq_length=None, eval_text_key=None, eval_tokens=1000000, fp32_embedding=False, fp32_layernorm=False, fp32_tokentypes=False, hidden_dropout=0.0, hidden_size=1024, incremental=False, intermediate_size=None, layernorm_epsilon=1e-12, lazy_loader=True, load=None, load_all_rng=False, load_optim=True, load_rng=True, local_rank=None, log_interval=1000000, loose_json=False, lr=0.0001, lr_decay_iters=None, lr_decay_style='linear', max_dataset_size=None, max_position_embeddings=512, max_preds_per_seq=80, model_type='rg+mlm', modes='mlm,rg', no_aux=False, num_attention_heads=16, num_layers=24, num_workers=22, presplit_sentences=True, pretrained_bert=False, rank=0, resume_dataloader=False, save='pretrained_berts/rg+mlm', save_all_rng=False, save_iters=None, save_optim=True, save_rng=True, seed=1234, seq_length=128, shuffle=True, split='1000,1,1', test_data=None, text_key='text', tokenizer_model_type='bert-base-uncased', tokenizer_path='tokenizer.model', tokenizer_type='BertWordPieceTokenizer', track_results=True, train_data=['bert_corpus'], train_iters=1000000, train_tokens=1000000000, use_tfrecords=False, valid_data=None, vocab_size=30522, warmup=0.01, weight_decay=0.02, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = configure_data()\n",
    "data_config.set_defaults(data_set_type='BERT', transpose=False)\n",
    "(train_data, val_data, test_data), tokenizer = data_config.apply(args)\n",
    "args.data_size = tokenizer.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colour import Color\n",
    "white = Color(\"white\")\n",
    "red = Color(\"red\")\n",
    "color_list=list(white.range_to(red, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'max_token_hidden'\n",
    "import pickle\n",
    "with open('embeds/raw_val.pkl', 'rb') as handle:\n",
    "    raw_text = pickle.load(handle)\n",
    "    \n",
    "with open('grads/{}/view_1'.format(model), 'rb') as handle:\n",
    "    grads_1= pickle.load(handle)\n",
    "    \n",
    "with open('grads/{}/view_2'.format(model), 'rb') as handle:\n",
    "    grads_2= pickle.load(handle)\n",
    "    \n",
    "with open('grads/{}/view_3'.format(model), 'rb') as handle:\n",
    "    grads_3= pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_sequence(tokens):\n",
    "    \"\"\"\n",
    "    Truncate sequence pair\n",
    "    \"\"\"\n",
    "    max_num_tokens = val_data.dataset.max_seq_len-2-3\n",
    "    while True:\n",
    "        if len(tokens) <= max_num_tokens:\n",
    "            break\n",
    "        idx = 0 if random.random() < 0.5 else len(tokens) - 1\n",
    "        tokens.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def get_color_map(grad):\n",
    "    grad=grad/grad.sum()\n",
    "    grad=grad*255\n",
    "    res=[]\n",
    "    color_index=0\n",
    "    d={}\n",
    "    for i in np.argsort(grad):\n",
    "        color_index+=int(grad[i])\n",
    "        d[i]=color_list[color_index]\n",
    "    return d\n",
    "\n",
    "def printmd(token, color_map, init_text=None):\n",
    "    if init_text:\n",
    "        res=[init_text]\n",
    "    else:\n",
    "        res=[]\n",
    "    for index, token_id in enumerate(token):\n",
    "        string=tokenizer.IdToToken(token_id)\n",
    "        color=color_map[index]\n",
    "        colorstr = \"<span style='background-color:{}'>{}</span>\".format(color, string) \n",
    "        res.append(colorstr)\n",
    "    display(Markdown(\" \".join(res)))\n",
    "\n",
    "def grad_mapping(index):\n",
    "    text=raw_text[index]\n",
    "    \n",
    "    token=tokenizer.EncodeAsIds(text)\n",
    "    truncate_sequence(token)\n",
    "    d_1=get_color_map(grads_1[index])\n",
    "    d_2=get_color_map(grads_2[index])\n",
    "    d_3=get_color_map(grads_3[index])\n",
    "    print('Raw text: ', text)\n",
    "    \n",
    "    printmd(token, d_1, 'Facet 1: ')\n",
    "    printmd(token, d_2, 'Facet 2: ')\n",
    "    printmd(token, d_3, 'Facet 3: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_id = random.randint(0,len(raw_text)-1)\n",
    "grad_mapping(choose_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
